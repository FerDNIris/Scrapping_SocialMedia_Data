{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium as sel\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.firefox.options import Options as firefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de Selenium\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.binary_location = r'E:/Users/1167486/Local/Drivers_web/chrome-win64/chrome.exe'\n",
    "    chrome_options.add_argument(\"--headless\")  \n",
    "    chrome_options.add_argument(\"--disable-notifications\")\n",
    "    chrome_options.add_argument(\"--lang=es\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    \n",
    "    #firefox_options = firefoxOptions()\n",
    "    #firefox_options.add_argument(\"--headless\")  \n",
    "    #firefox_options.add_argument(\"--disable-notifications\")\n",
    "    #firefox_options.add_argument(\"--lang=es\")\n",
    "    #firefox_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "    service = Service('E:/Users/1167486/Local/Drivers_web/chromedriver-win64/chromedriver.exe')  \n",
    "    #service = Service('E:/Users/1167486/Local/Drivers_web/geckodriver.exe')\n",
    "    #driver = webdriver.Chrome(service=service, options=firefox_options)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlTwitter='https://x.com/RicardoBSalinas/status/1900807572610818356'\n",
    "urlTwitter = 'https://x.com/f_solorzano/status/1896405011846098960'\n",
    "#driver.get(urlTwitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urlTwitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"css-146c3p1 r-bcqeeo r-1ttztb7 r-qvutc0 r-37j5jr r-1inkyih r-16dba41 r-bnwqim r-135wba7\" data-testid=\"tweetText\" dir=\"auto\" id=\"id__qxyoihzzb9\" lang=\"es\" style=\"color: rgb(15, 20, 25);\"><span class=\"css-1jxf684 r-bcqeeo r-1ttztb7 r-qvutc0 r-poiln3\">El mejor premio de la noche: Mikey Madison.</span></div>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', {'data-testid' : 'tweetText'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweet_comments(tweet_url, max_comments=100):\n",
    "    driver = setup_driver()\n",
    "    comments = []\n",
    "    \n",
    "    try:\n",
    "        driver.get(tweet_url)\n",
    "        time.sleep(5) \n",
    "        \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        comments_collected = 0\n",
    "        \n",
    "        while comments_collected < max_comments:\n",
    "            # Obtener el HTML de la página\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            #comment_elements = soup.find_all('div', {'data-testid': 'tweetText'})\n",
    "            comment_elements = soup.find_all('div', {'data-testid': 'cellInnerDiv'})\n",
    "            \n",
    "            for comment in comment_elements:\n",
    "                if comment.text not in comments and len(comment.text) > 5:\n",
    "                    comments.append(comment.text)\n",
    "                    comments_collected += 1\n",
    "                    if comments_collected >= max_comments:\n",
    "                        break\n",
    "            \n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2) \n",
    "            \n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el scraping: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweet_comments(tweet_url, max_comments=100):\n",
    "    driver = setup_driver()\n",
    "    comments = []\n",
    "\n",
    "    try:\n",
    "        driver.get(tweet_url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        comments_collected = 0\n",
    "\n",
    "        while comments_collected < max_comments:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Intenta identificar los comentarios con selectores más específicos\n",
    "            comment_elements = soup.find_all('div', {'data-testid': 'tweetText'})\n",
    "\n",
    "            for comment in comment_elements:\n",
    "                comment_text = comment.text.strip()\n",
    "                if comment_text and comment_text not in comments:\n",
    "                    comments.append(comment_text)\n",
    "                    comments_collected += 1\n",
    "                    if comments_collected >= max_comments:\n",
    "                        break\n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el scraping: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = scrape_tweet_comments(tweet_url=urlTwitter,  max_comments=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El mejor premio de la noche: Mikey Madison.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"screen_name\": \"f_solorzano\",\n",
    "    \"count\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://api.twitter.com/1.1/statuses/user_timeline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url_api, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': [{'code': 215, 'message': 'Bad Authentication data.'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
